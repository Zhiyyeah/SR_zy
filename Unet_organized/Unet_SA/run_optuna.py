import optuna
import torch
import torch.nn as nn
import torch.optim as optim

from model_attention import UNetSA
from data_loader import create_train_test_dataloaders
from metrics import psnr
from utils import get_device

# ========== å›ºå®šå‚æ•° ==========
max_epochs = 10
up_scale = 8
device = get_device()

optuna.logging.set_verbosity(optuna.logging.INFO)

# ========== è®­ç»ƒå‡½æ•° ==========
def train_one_trial(model, train_loader, test_loader, optimizer, criterion, device, trial):
    model = model.to(device)
    model.train()

    for epoch in range(max_epochs):
        for lr_imgs, hr_imgs in train_loader:
            lr_imgs = lr_imgs.to(device)
            hr_imgs = hr_imgs.to(device)

            optimizer.zero_grad()
            sr_imgs = model(lr_imgs)
            loss = criterion(sr_imgs, hr_imgs)
            loss.backward()
            optimizer.step()

        # è®¡ç®—éªŒè¯é›† PSNR
        model.eval()
        total_psnr = 0.0
        count = 0
        with torch.no_grad():
            for lr_imgs, hr_imgs in test_loader:
                lr_imgs = lr_imgs.to(device)
                hr_imgs = hr_imgs.to(device)
                sr_imgs = model(lr_imgs)
                batch_psnr = psnr(hr_imgs, sr_imgs)
                total_psnr += batch_psnr
                count += 1
        avg_psnr = total_psnr / count

        # è¾“å‡º PSNR
        print(f"ğŸŸ¦ Trial {trial.number} | Epoch {epoch+1}/{max_epochs} | Val PSNR: {avg_psnr:.2f} dB", flush=True)

        # ç¬¬ä¸€è½®è¡¨ç°å¤ªå·®ç›´æ¥è·³è¿‡
        if epoch == 0 and avg_psnr < 35:
            print(f"â›” Trial {trial.number} è¢«è·³è¿‡ï¼šç¬¬1è½® PSNR={avg_psnr:.2f} < 35", flush=True)
            raise optuna.exceptions.TrialPruned()

        # Optuna å‰ªææœºåˆ¶
        trial.report(-avg_psnr, step=epoch)
        if trial.should_prune():
            print(f"âŒ Trial {trial.number} è¢«å‰ªæäº Epoch {epoch+1}", flush=True)
            raise optuna.exceptions.TrialPruned()

        model.train()

    return avg_psnr

# ========== ç›®æ ‡å‡½æ•° ==========
def objective(trial):
    lr = trial.suggest_float("lr", 1e-5, 1e-3, log=True)
    width = trial.suggest_categorical("width", [32, 64, 96])
    batch_size = trial.suggest_categorical("batch_size", [8, 16, 32])
    loss_type = trial.suggest_categorical("loss_type", ["MSE", "L1"])

    print(f"\nğŸ“‹ Trial {trial.number} | lr={lr:.5e}, width={width}, batch_size={batch_size}, loss={loss_type}", flush=True)

    train_loader, test_loader = create_train_test_dataloaders(
        lr_dir='/home/zyye/SR_backup/Imagery/Water_TOA_tiles_lr',
        hr_dir='/home/zyye/SR_backup/Imagery/Water_TOA_tiles',
        batch_size=batch_size,
        train_ratio=0.8
    )

    model = UNetSA(up_scale=up_scale, width=width)
    optimizer = optim.Adam(model.parameters(), lr=lr)

    if loss_type == "MSE":
        criterion = nn.MSELoss()
    else:
        criterion = nn.L1Loss()

    val_psnr = train_one_trial(model, train_loader, test_loader, optimizer, criterion, device, trial)
    print(f"âœ… Trial {trial.number} å®Œæˆ | Final Val PSNR: {val_psnr:.2f} dB", flush=True)
    return -val_psnr

# ========== ä¸»æµç¨‹ ==========
if __name__ == "__main__":
    pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=2)
    study = optuna.create_study(direction="minimize", pruner=pruner)
    study.optimize(objective, n_trials=500)

    print("\nğŸ¯ æœ€ä½³å‚æ•°ï¼š", study.best_trial.params, flush=True)
    print("ğŸ† æœ€ä½³éªŒè¯ PSNRï¼š", -study.best_trial.value, flush=True)
