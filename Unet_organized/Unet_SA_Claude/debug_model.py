import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np
from model_attention import UNetSA
from data_loader import create_train_val_test_dataloaders

def test_model_with_real_data():
    """ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•æ¨¡å‹"""
    print("ğŸ”¬ ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•æ¨¡å‹...")
    
    # åŠ è½½çœŸå®æ•°æ®
    lr_dir = r"D:\Py_Code\Unet_SR\SR_zy\Imagey\Imagery_WaterLand\WaterLand_TOA_tiles_lr"
    hr_dir = r"D:\Py_Code\Unet_SR\SR_zy\Imagey\Imagery_WaterLand\WaterLand_TOA_tiles_hr"
    
    train_loader, _, _ = create_train_val_test_dataloaders(
        lr_dir, hr_dir, batch_size=1, 
        train_ratio=0.7, val_ratio=0.15, test_ratio=0.15,
        seed=42, num_workers=0, pin_memory=False
    )
    
    # è·å–ä¸€ä¸ªçœŸå®æ ·æœ¬
    lr_real, hr_real = next(iter(train_loader))
    
    print(f"çœŸå®LRèŒƒå›´: [{lr_real.min():.6f}, {lr_real.max():.6f}]")
    print(f"çœŸå®HRèŒƒå›´: [{hr_real.min():.6f}, {hr_real.max():.6f}]")
    
    # åˆ›å»ºæœªè®­ç»ƒçš„æ¨¡å‹
    model = UNetSA(up_scale=8, img_channel=7, width=64, dropout_rate=0.1)
    model.eval()
    
    with torch.no_grad():
        # æµ‹è¯•æ¨¡å‹å„ä¸ªç»„ä»¶
        print("\nğŸ” åˆ†ææ¨¡å‹å„ä¸ªç»„ä»¶:")
        
        # 1. åŒçº¿æ€§æ’å€¼åŸºçº¿
        up_input = F.interpolate(lr_real, scale_factor=8, mode='bilinear', align_corners=False)
        print(f"åŒçº¿æ€§æ’å€¼ç»“æœèŒƒå›´: [{up_input.min():.6f}, {up_input.max():.6f}]")
        
        # 2. å®Œæ•´æ¨¡å‹è¾“å‡º
        sr_output = model(lr_real)
        print(f"æ¨¡å‹å®Œæ•´è¾“å‡ºèŒƒå›´: [{sr_output.min():.6f}, {sr_output.max():.6f}]")
        
        # 3. åˆ†ææ®‹å·®è¿æ¥
        # æˆ‘ä»¬éœ€è¦ä¿®æ”¹æ¨¡å‹æ¥è·å–æ®‹å·®éƒ¨åˆ†
        # å…ˆè·å–æ¨¡å‹å†…éƒ¨çš„æ®‹å·®é¢„æµ‹
        x = model._check_image_size(lr_real)
        up_input_internal = F.interpolate(x, scale_factor=model.up_scale, mode='bilinear', align_corners=False)
        
        # ç¼–ç éƒ¨åˆ†
        x1 = model.input_conv(x)
        x2 = model.down1(x1)
        x3 = model.down2(x2)
        x4 = model.down3(x3)
        x5 = model.down4(x4)
        
        if model.use_attention:
            x5 = model.bottleneck_att(x5)
        
        # è§£ç éƒ¨åˆ†
        x = model.up1(x5, x4)
        x = model.up2(x, x3)
        x = model.up3(x, x2)
        x = model.up4(x, x1)
        
        # è¶…åˆ†è¾¨ç‡éƒ¨åˆ†
        x = model.sr_up1(x)
        x = model.sr_up2(x)
        x = model.sr_up3(x)
        x = model.output_conv(x)
        if model.use_attention:
            x = model.final_att(x)
        
        # è¿™æ˜¯æ®‹å·®éƒ¨åˆ†ï¼ˆæ¨¡å‹å­¦ä¹ çš„å¢é‡ï¼‰
        residual = x
        print(f"æ¨¡å‹å­¦ä¹ çš„æ®‹å·®èŒƒå›´: [{residual.min():.6f}, {residual.max():.6f}]")
        print(f"æ®‹å·®å‡å€¼: {residual.mean():.6f}")
        print(f"æ®‹å·®æ ‡å‡†å·®: {residual.std():.6f}")
        
        # æœ€ç»ˆè¾“å‡º = æ®‹å·® + åŒçº¿æ€§æ’å€¼
        final_output = residual + up_input_internal
        print(f"æœ€ç»ˆè¾“å‡ºèŒƒå›´: [{final_output.min():.6f}, {final_output.max():.6f}]")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
        if torch.isnan(final_output).any():
            print("âš ï¸ è­¦å‘Š: è¾“å‡ºåŒ…å«NaN!")
        if torch.isinf(final_output).any():
            print("âš ï¸ è­¦å‘Š: è¾“å‡ºåŒ…å«Inf!")

def test_loss_scale():
    """æµ‹è¯•æŸå¤±å‡½æ•°çš„å°ºåº¦"""
    print("\nğŸ“ æµ‹è¯•æŸå¤±å‡½æ•°å°ºåº¦:")
    
    # æ¨¡æ‹ŸçœŸå®æ•°æ®èŒƒå›´çš„æŸå¤±
    hr_sim = torch.rand(1, 7, 512, 512) * 0.18 + 0.003  # 0.003-0.18èŒƒå›´
    sr_sim = torch.rand(1, 7, 512, 512) * 0.18 + 0.003
    
    mse_loss = torch.nn.MSELoss()
    loss_real_scale = mse_loss(sr_sim, hr_sim)
    
    print(f"çœŸå®æ•°æ®å°ºåº¦çš„MSEæŸå¤±: {loss_real_scale.item():.8f}")
    
    # å¦‚æœæŸå¤±å¾ˆå°ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ ç‡æˆ–æŸå¤±å‡½æ•°
    if loss_real_scale.item() < 1e-4:
        print("âš ï¸ è­¦å‘Š: æŸå¤±å€¼éå¸¸å°ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ ç‡æˆ–ä½¿ç”¨ä¸åŒçš„æŸå¤±å‡½æ•°")

def analyze_gradient_flow():
    """åˆ†ææ¢¯åº¦æµ"""
    print("\nğŸŒŠ åˆ†ææ¢¯åº¦æµ:")
    
    # åˆ›å»ºæ¨¡å‹
    model = UNetSA(up_scale=8, img_channel=7, width=64, dropout_rate=0.1)
    
    # åˆ›å»ºçœŸå®èŒƒå›´çš„è¾“å…¥å’Œç›®æ ‡
    lr_input = torch.rand(1, 7, 64, 64) * 0.18 + 0.003
    hr_target = torch.rand(1, 7, 512, 512) * 0.18 + 0.003
    
    lr_input.requires_grad_(True)
    
    # å‰å‘ä¼ æ’­
    sr_output = model(lr_input)
    
    # è®¡ç®—æŸå¤±
    criterion = torch.nn.MSELoss()
    loss = criterion(sr_output, hr_target)
    
    print(f"è¾“å…¥èŒƒå›´: [{lr_input.min():.6f}, {lr_input.max():.6f}]")
    print(f"è¾“å‡ºèŒƒå›´: [{sr_output.min():.6f}, {sr_output.max():.6f}]")
    print(f"ç›®æ ‡èŒƒå›´: [{hr_target.min():.6f}, {hr_target.max():.6f}]")
    print(f"æŸå¤±å€¼: {loss.item():.8f}")
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    if lr_input.grad is not None:
        grad_norm = lr_input.grad.norm().item()
        print(f"è¾“å…¥æ¢¯åº¦èŒƒæ•°: {grad_norm:.8f}")
        
        if grad_norm > 100:
            print("âš ï¸ è­¦å‘Š: æ¢¯åº¦å¯èƒ½è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸")
        elif grad_norm < 1e-8:
            print("âš ï¸ è­¦å‘Š: æ¢¯åº¦è¿‡å°ï¼Œå¯èƒ½å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±")

def visualize_model_behavior():
    """å¯è§†åŒ–æ¨¡å‹è¡Œä¸º"""
    print("\nğŸ“Š å¯è§†åŒ–æ¨¡å‹è¡Œä¸º:")
    
    # åŠ è½½çœŸå®æ•°æ®
    lr_dir = r"D:\Py_Code\Unet_SR\SR_zy\Imagey\Imagery_WaterLand\WaterLand_TOA_tiles_lr"
    hr_dir = r"D:\Py_Code\Unet_SR\SR_zy\Imagey\Imagery_WaterLand\WaterLand_TOA_tiles_hr"
    
    train_loader, _, _ = create_train_val_test_dataloaders(
        lr_dir, hr_dir, batch_size=1, 
        train_ratio=0.7, val_ratio=0.15, test_ratio=0.15,
        seed=42, num_workers=0, pin_memory=False
    )
    
    lr_real, hr_real = next(iter(train_loader))
    
    # æœªè®­ç»ƒæ¨¡å‹
    model = UNetSA(up_scale=8, img_channel=7, width=64, dropout_rate=0.1)
    model.eval()
    
    with torch.no_grad():
        sr_output = model(lr_real)
        
        # åŒçº¿æ€§æ’å€¼ä½œä¸ºåŸºçº¿
        bilinear = F.interpolate(lr_real, scale_factor=8, mode='bilinear', align_corners=False)
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªé€šé“è¿›è¡Œå¯è§†åŒ–
        lr_img = lr_real[0, 0].numpy()
        hr_img = hr_real[0, 0].numpy()
        sr_img = sr_output[0, 0].numpy()
        bi_img = bilinear[0, 0].numpy()
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # LR
        im1 = axes[0, 0].imshow(lr_img, cmap='gray')
        axes[0, 0].set_title(f'LR Input\nRange: [{lr_img.min():.4f}, {lr_img.max():.4f}]')
        plt.colorbar(im1, ax=axes[0, 0])
        
        # HR Ground Truth
        im2 = axes[0, 1].imshow(hr_img, cmap='gray')
        axes[0, 1].set_title(f'HR Ground Truth\nRange: [{hr_img.min():.4f}, {hr_img.max():.4f}]')
        plt.colorbar(im2, ax=axes[0, 1])
        
        # Bilinear Interpolation
        im3 = axes[1, 0].imshow(bi_img, cmap='gray')
        axes[1, 0].set_title(f'Bilinear Interpolation\nRange: [{bi_img.min():.4f}, {bi_img.max():.4f}]')
        plt.colorbar(im3, ax=axes[1, 0])
        
        # Model Output
        im4 = axes[1, 1].imshow(sr_img, cmap='gray')
        axes[1, 1].set_title(f'Model Output (Untrained)\nRange: [{sr_img.min():.4f}, {sr_img.max():.4f}]')
        plt.colorbar(im4, ax=axes[1, 1])
        
        plt.tight_layout()
        plt.savefig('model_behavior_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("âœ… æ¨¡å‹è¡Œä¸ºåˆ†æå›¾å·²ä¿å­˜ä¸º 'model_behavior_analysis.png'")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ¨¡å‹æ®‹å·®è¿æ¥å’Œè¡Œä¸ºåˆ†æ...")
    
    try:
        # 1. ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•æ¨¡å‹
        test_model_with_real_data()
        
        # 2. æµ‹è¯•æŸå¤±å‡½æ•°å°ºåº¦
        test_loss_scale()
        
        # 3. åˆ†ææ¢¯åº¦æµ
        analyze_gradient_flow()
        
        # 4. å¯è§†åŒ–æ¨¡å‹è¡Œä¸º
        visualize_model_behavior()
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()